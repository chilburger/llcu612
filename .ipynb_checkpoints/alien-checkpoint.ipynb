{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alien \n",
    "Mini-assignment #5: Collocates\n",
    "\n",
    "<b>Directions recap:</b><p>\n",
    "Using the Internet Movie Script Database (IMSDb) screenplay of Alien (1976), try out the various tools in Voyant that use collocate information (Links, TermsBerry & Collocates). Note frequent words (top 5) to compare with the Jupyter portion of the assignment. Consider looking at the words “Alien” and “Ship” to start with. Explore.\n",
    "\n",
    "Next, in Jupyter, complete the following steps:\n",
    "\n",
    "1. Import the NLTK Library *See Getting NLTK in the Art of Literary Text Mining with Jupyter*\n",
    "2. Import the Alien .txt file (details below)\n",
    "      a. Start by copying the Alien script into a text editor and save as a .txt file locally\n",
    "      b. Import the .txt file into Jupyter\n",
    "3. Isolate script (remove synopsis, the cast of characters, stage directions, etc.) as best as you can\n",
    "4. Perform word tokenization to the text (all words)\n",
    "5. Create a dictionary for the word frequencies and note the top 5 frequent words\n",
    "      a. load stop-words from NLTK library\n",
    "6. Create concordance of the word “Alien” (5 lines) and the word “Ship”\n",
    "\n",
    "In the submission box with your link to the mini-assignment notebook, also note any differences of word frequencies you found between Voyant and Jupyter, as well as any other interesting findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      ALIEN\n",
      "\n",
      "\n",
      "                  (project formerly titled STARBEAST)\n",
      "\n",
      "\n",
      "                Story by Dan O'Bannon & Ronald Shusett\n",
      "\n",
      "\n",
      "       \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "directory = \"alien\"\n",
    "with open(\"alien/alien.txt\", \"r\") as f:\n",
    "   alienString = f.read()\n",
    "print(alienString[:150])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lines above import the alien text and prints a short preview."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' has waited centuries to contact another form of intelligent\\n     life in the universe -- they decide to land and investigate.  Their\\n     search takes them to a wrecked alien spacecraft whose doors gape open\\n     -- it is dead and abandoned.  Inside they find, among other strange\\n     things, the skeleton of one of the unearthly space travellers.\\n\\n     Certain clues in the wrecked ship lead them across the hostile surface\\n     of the planet to a primitive stone pyramid, the only remnant of a\\n  '"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "capsRemoved = re.sub(r'\\b[A-Z]+\\b', '', alienString) #removes the full CAPS words. Character names,stage directions, etc.\n",
    "capsRemoved[500:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I remove the full capitalzied words, which in this screenplay notate the speaking characters and stage directions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer #this tokenizer was required to handle contractions, ie. \"don't\"\n",
    "tknzr = TweetTokenizer()\n",
    "alienTokensLowercase = tknzr.tokenize(capsRemoved.lower()) #converts entire string to lowercase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is where I do the tokenization step. I used this tokenizer because it allowed for me to work with contractions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words(\"english\") #creates a list of stopwords to use for filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I had to create a stopwords list so that I could remove them in the following step below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     roby  standard      ship broussard     thing \n",
      "      124       112        61        59        58 \n"
     ]
    }
   ],
   "source": [
    "alienRealContentWordTokensLowercase = [word for word in alienTokensLowercase \\\n",
    "        if word[0].isalpha() and word not in stopwords] #creates new list of real content words\n",
    "alienRealContentWordFrequencies = nltk.FreqDist(alienRealContentWordTokensLowercase) #checks frequency\n",
    "alienRealContentWordFrequencies.tabulate(5) #top 5 frequent words tabulated\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we ignored stop words and tokenized all other real words. I then took the frequency and tabulated the top 5 most frequently used words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 5 of 61 matches:\n",
      "llers . certain clues in the wrecked ship lead them across the hostile surface\n",
      "tal - - they dare not kill it on the ship . ultimately it is dislodged from it\n",
      "from its victim and ejected from the ship , and they blast off from the hell-p\n",
      "asite ... and now it is loose on the ship . series of ghastly adventures follo\n",
      "crushed in the air lock door and the ship loses most of its air in a terrific \n"
     ]
    }
   ],
   "source": [
    "alienText = nltk.Text(alienTokensLowercase)\n",
    "alienText.concordance(\"ship\", lines=5) #gives 5 lines of concordance with using the word \"ship\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 5 of 8 matches:\n",
      "ship intercepts a transmission in an alien language , originating from a nearby\n",
      "their search takes them to a wrecked alien spacecraft whose doors gape open - -\n",
      "ho will reach earth alive - - man or alien . , captain ... leader and a politic\n",
      "elligence . if there is some kind of alien intelligence down on that planetoid \n",
      " approach it . they start toward the alien ship . - - ( ' ) ( over , filtered )\n"
     ]
    }
   ],
   "source": [
    "alienText.concordance(\"alien\", lines=5) #gives 5 lines of concordance with using the word \"alien\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, I used concordance on the words \"ship\" and \"alien\" to look more closely at the context of the words. Doing this, I am able to see that they didn't follow the all caps rule for some of the stage directions, as the 4th line appears to be stage directions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
